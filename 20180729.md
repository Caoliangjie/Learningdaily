### Two stream convolutional networks for action recognization in videos论文阅读
双流convnet结构（空间-时间网络）
这篇论文讲的挑战静止帧和动作的外观补充信息。
### 想法
1. 作者提出双流convnet结构，结合时间空间网络（时间负责弄图片，空间搞视频）。（双流包括腹流层和被侧层，前者负责识别目标，后者负责识别运动）
2. 证明在多帧秘籍光流集上训练的convnet能训练的很好。
3.  用deep convolutional networks 来做。
### two-stream架构
光流，是空间运动提在屏显示的像素运动的瞬时速度，研究光溜主要目的是从图片序列中近似得的到不能直接得到的运动场。 一个视频会很容易的被拆成空间部分和时间部分。作者这里用两种融合的方法，求平均，在多类线性SVM上训练，用L2正则化的sofanax计算特征分数。
two-stream是根据人体视觉皮层包含的两个途径分出来的。
### 光流卷积网络
大概就是对一个时间段进行识别（光流概念）
光流叠加：一个密集光流可以表现为连续帧t和下一帧t+1的3
D集合。在帧t的位置用dt（u，v）表示为位移矢量，然后对移动的下一帧也有具体的变化。帧进行得加之后，变成一个流畅的视频，用公式L（u，v，c）表示了最后的动作信息（我理解的是，如果对于行为理解，图片算是矩阵变化的话，连续的一个行为应该对应的矩阵的变化应该是差不多的，同加或者同减之类的？然后就是要有一段时间序列）
### 时间卷积网络
为了表现出视频表示的联系，给予特定的编码方式用光流进行计算。深度网络而言，把其整合为卷积网络就是为了保证一段时间的动作变化更加精确。（用卷积扩大了面积方便找到？）
### 多任务学习
时间卷积网络要用视频数据集训练，为了表现出能学习一个视频，需要用大量的视频数据集进行训练（比如UCF-101和HMDB-51）,。按照卷积神经网络的做法进行计算，三个层面，把loss降下来即可。
### 实现的细节（讲真很懵逼，因为环境都不好搭建，改天申请一下服务器咯）
卷积神经网络的配置：隐藏层采用的是RELU激活函数，池化层用maxpooling，窗口为3*3，stride为2。
训练过程：在caffe上实现，如果可以有cpu版本的caffe的话。
更新：最后还是安上了cpu版本的caffe。
在ImageNet上进行预训练，分好测试集和训练集。
多个GPU训练：我没有好的gpu，所以只能放弃这个想法咯。
### 验证
分两块（空间卷积网络和时间卷积网络）
时间网络的多任务学习，要用视频训练集，但是因为行为的训练集很少，只能进行多次变化，创建多任务扩大训练集。
Two-stream网络，结合两个识别流，因此结论是：
（1）时间和空间识别流是互补的，他们的融合明显的提高了彼此（时间网络上提高了6%，空间网络上提高了14%）。
（2）基于SVM的softmax计分融合要比平均融合做的要好。
（3）使用双向流对于卷积网络的情况没有益处。
（4）使用多任务训练的时间卷积网络要比单独或者是融合一个空间网络的性能都要好。
### 对比
其实我也不懂这些最先进的东西到底是什么，但是数据表明是这个大哥的算法比较快，当然大佬毕竟还是大佬，能够提出这种双网的卷积神经网络本身就是一种创举，随后经过严谨的科学实验测试并标明这种创新能够实现很好地效果，这个是可复制的，然而文章的这种创新则不是很容易复制。那么不管原文在不同部分的篇幅比例多么偏差，我们把关注点回到作者这个创新的双流神经网络，它的提出，按照作者说的，也是基于生物学的相关理论模仿得到的，这是作者眼中的创新的来源。（神经学的问题吧....）
### 我的结论
还是说的先搭建好环境，然后Python赶紧瞅瞅....真拖这个大哥后腿也不是什么好事啊....文章讲真真的看不太懂，还有一篇明天好好学习一番写下paper reading。
