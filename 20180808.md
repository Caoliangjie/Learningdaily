## Python学习
集合和操作:集合是多个元素的无序组合.建立空集合时必须定义set(),有小括号表示的叫做元组.特点:
集合不能包含相同元素.集合每个用大括号表示,集合元素之间是无序的.
集合和数学上一样,也有所谓的交集,并集,补集之类的.
A集合减去B集合的结果是两者差的元素.(无序)
集合操作:
s.add(x),将不在s中的x加入到s. s.discard(x)移除s中元素x,如果x不在集合s中,不报错.其他的和list操作差不太多.x in s,x not in s这几个也是常见的.
```
try:
    while True:
         print(A.pop(),end="")
 except:
       pass
```
上面这段代码就是不断从A中取出元素打印,包含关系.
数据去重:对于列表去除重复的元素,可以用集合的方式.
比如ls=["p","p"],s=set(ls),这样直接就会把重复的元素去除.
###  序列
基类类型,包括扩展到字符串,元组,列表等等......
### jieba库的使用
进行中文分词,第三方库,运用了pip进行安装.精确模式,全模式,搜索引擎模式.三种模式.
常用函数:jieba.lcut(S),精确模式,返回一个列表类型的分词结果.
jieba.lcut(s,cut_all=True),全模式,会存在冗余.
jieba.lcut_for_search(s)搜索引擎模式,返回一个列表类型的分词结果,存在冗余.
jieba.add_word(w),向粉刺词典添加新单词.
例子:
Hamlet的文本(单词)统计.
```
def getext():
    txt=open("hamlet.txt","r").read()
    txt=txt.lower()##全部变成小写
    for ch in '!"#$%&*()*+,-/.:;><=@?[\\]~_{}~`|':
        txt=txt.replace(ch," ")
    return txt
hamelettxt=getext()
words=hamelettxt.split()
counts={}
for word in words:
    counts[word]=counts.get(word,1)+1##用字典统计元素出现的次数.
items=list(counts.items())
items.sort(key=lambda x:x[1],reverse=True)
for i in range(10):
    word,count=items[i]##这里改变取得词是哪一个
    print("{0:<10}-{1:>5}".format(word,count))
```
并不是很长,仔细看看就会明白文件的操作方式以及最后的统计情况.
 但是用jieba确实是搞得太jieba,分出来这些词会非常垃圾.要改造一下,输出自己需要的词.
 文本词频统计,我们可以扩展到任意的这些文本.
### python练习题
函数并不是计算机对代码执行优化的要求,函数优化的话如果用不到函数那就是最简单的.
递归的特征:基例需要多次递归循环.
递归循环执行效率并没有想象中那么高.如果能用直接的代码写出来的话,为什么非得递归呢,递归可能只是省了写多行代码的痛苦.
对于函数了解不一定非得了解其内部实现过程,也就是说你只需要知道他是干什么的,我管你里面写的是什么玩意.
S|T代表的是并集运算,记住了.
对于S.pop(),给定参数时,S.pop(i)只是把他移除,不是取回.
s.index(x)返回的是索引,第一次x出现的序号.
ls.append()确实只能在最后加上这个元素,不能加上别的.
x in d,当x为字典时,是判断x是否是字典中的键.