## lstm行为识别代码分析
```
import numpy as np  ###这边主要是规定一些宏包（numpy数组，matplotlib数学画图，tensorflow框架）
import matplotlib
import matplotlib.pyplot as plt
import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)
from sklearn import metrics

import os
```
引入的宏包，这里的代码分析是针对lstm这一二个方法来进行的。
```
# Useful Constants
# Those are separate normalised input features for the neural network（相当于是初始化这些类标）
INPUT_SIGNAL_TYPES = [
    "body_acc_x_",
    "body_acc_y_",
    "body_acc_z_",
    "body_gyro_x_",
    "body_gyro_y_",
    "body_gyro_z_",
    "total_acc_x_",
    "total_acc_y_",
    "total_acc_z_"
]

# Output classes to learn how to classify
LABELS = [
    "WALKING", 
    "WALKING_UPSTAIRS", 
    "WALKING_DOWNSTAIRS", 
    "SITTING", 
    "STANDING", 
    "LAYING"
] 
```
这一块是把常量设置好然后打好标签。
```
# Note: Linux bash commands start with a "!" inside those "ipython notebook" cells

DATA_PATH = "data/"#下载的数据集放的地方，可以自己修改路径#

!pwd && ls
os.chdir(DATA_PATH)##os.chdir() 方法用于改变当前工作目录到指定的路径。
!pwd && ls

!python download_dataset.py

!pwd && ls
os.chdir("..")
!pwd && ls

DATASET_PATH = DATA_PATH + "UCI HAR Dataset/"
print("\n" + "Dataset is now located at: " + DATASET_PATH)
```
这里解释的也比较清楚，然而这里下载的数据集是什么玩意....没有一个是视频还是说我需要自己添加进来。但是里面全是txt文件就不是很理解。
```
TRAIN = "train/"##训练集放的地方
TEST = "test/"##测试集放的地方


# Load "X" (the neural network's training and testing inputs)加载训练的输入和输出

def load_X(X_signals_paths):##加载函数，读取路径
    X_signals = []##
    
    for signal_type_path in X_signals_paths:
        file = open(signal_type_path, 'r')##打开文件
        # Read dataset from disk, dealing with text files' syntax
        X_signals.append(
            [np.array(serie, dtype=np.float32) for serie in [
                row.replace('  ', ' ').strip().split(' ') for row in file
            ]]
        )
        file.close()##关闭文件
    
    return np.transpose(np.array(X_signals), (1, 2, 0))

X_train_signals_paths = [
    DATASET_PATH + TRAIN + "Inertial Signals/" + signal + "train.txt" for signal in INPUT_SIGNAL_TYPES
]##x的训练集路径
X_test_signals_paths = [
    DATASET_PATH + TEST + "Inertial Signals/" + signal + "test.txt" for signal in INPUT_SIGNAL_TYPES
]##x的测试集路径

X_train = load_X(X_train_signals_paths)
X_test = load_X(X_test_signals_paths)


# Load "y" (the neural network's training and testing outputs)y是输出，训练集和测试集的输出

def load_y(y_path):
    file = open(y_path, 'r')
    # Read dataset from disk, dealing with text file's syntax
    y_ = np.array(
        [elem for elem in [
            row.replace('  ', ' ').strip().split(' ') for row in file
        ]], ##规定维度
        dtype=np.int32
    )
    file.close()
    
    # Substract 1 to each output class for friendly 0-based indexing 
    return y_ - 1

y_train_path = DATASET_PATH + TRAIN + "y_train.txt"
y_test_path = DATASET_PATH + TEST + "y_test.txt"

y_train = load_y(y_train_path)
y_test = load_y(y_test_path)

```
讲述的也比较清楚，有一点就是这里读入的真的是txt文件，开头谈到的是运用的智能手机的数据集还是有lstmRNN，把这些化成了6类，上楼，走路，下楼，坐，站，躺这几类。
```
# Input Data 

training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)#一共有7352个类，这里因为没下数据集所以出不来结果#
test_data_count = len(X_test)  # 2947 testing series，2947个测试
n_steps = len(X_train[0])  # 128 timesteps per series 128步
n_input = len(X_train[0][0])  # 9 input parameters per timestep


# LSTM Neural Network's internal structure

n_hidden = 32 # Hidden layer num of features，隐藏层
n_classes = 6 # Total classes (should go up, or should go down)，总共数量是6类，作者之前也提过，就是上楼下楼这些基本的。


# Training 

learning_rate = 0.0025##学习率为0.0025
lambda_loss_amount = 0.0015##loss？
training_iters = training_data_count * 300  # Loop 300 times on the dataset
batch_size = 1500##batch-size为1500。
display_iter = 30000  # To show test set accuracy during training


# Some debugging info

print("Some useful info to get an insight on dataset's shape and normalisation:")##debug信息，方便判断执行到了哪一步
print("(X shape, y shape, every X's mean, every X's standard deviation)")
print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))
print("The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.")
```
这块没什么讲的，就是调用这个构建了一个RNN函数，最后一个one_hot是一个编码的函数，返回的还是浮点数。
```
# Graph input/output
x = tf.placeholder(tf.float32, [None, n_steps, n_input])##这里返回的是一个tensor类型，定义一个过程。
y = tf.placeholder(tf.float32, [None, n_classes])

# Graph weights
weights = {
    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights
    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))
}
biases = {
    'hidden': tf.Variable(tf.random_normal([n_hidden])),
    'out': tf.Variable(tf.random_normal([n_classes]))
}

pred = LSTM_RNN(x, weights, biases)

# Loss, optimizer and evaluation
l2 = lambda_loss_amount * sum(
    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()
) # L2 loss prevents this overkill neural network to overfit the data
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer

correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
```
tf.random_normal也是建立随机的大小。
这里是搭建的神经网络，这里还把权重给写好了，tf.variable是初始化，tf.random_normal用于从服从指定正态分布的数值中取出指定个数的值。
```
# To keep track of training's performance
test_losses = []
test_accuracies = []
train_losses = []
train_accuracies = []

# Launch the graph
sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))
init = tf.global_variables_initializer()
sess.run(init)

# Perform Training steps with "batch_size" amount of example data at each loop
step = 1
while step * batch_size <= training_iters:
    batch_xs =         extract_batch_size(X_train, step, batch_size)
    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size))

    # Fit training using batch data
    _, loss, acc = sess.run(
        [optimizer, cost, accuracy],
        feed_dict={
            x: batch_xs, 
            y: batch_ys
        }
    )
    train_losses.append(loss)
    train_accuracies.append(acc)
    
    # Evaluate network only at some steps for faster training: 
    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):
        
        # To not spam console, show training accuracy/loss in this "if"
        print("Training iter #" + str(step*batch_size) + \
              ":   Batch Loss = " + "{:.6f}".format(loss) + \
              ", Accuracy = {}".format(acc))
        
        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)
        loss, acc = sess.run(
            [cost, accuracy], 
            feed_dict={
                x: X_test,
                y: one_hot(y_test)
            }
        )
        test_losses.append(loss)
        test_accuracies.append(acc)
        print("PERFORMANCE ON TEST SET: " + \
              "Batch Loss = {}".format(loss) + \
              ", Accuracy = {}".format(acc))

    step += 1

print("Optimization Finished!")

# Accuracy for test data

one_hot_predictions, accuracy, final_loss = sess.run(
    [pred, accuracy, cost],
    feed_dict={
        x: X_test,
        y: one_hot(y_test)
    }
)

test_losses.append(final_loss)
test_accuracies.append(accuracy)

print("FINAL RESULT: " + \
      "Batch Loss = {}".format(final_loss) + \
      ", Accuracy = {}".format(accuracy))

```
训练自己的神经网络，这里要输出loss，accuracies，（包含train和test），这里竟然使用的画图？不太理解。tf.InteractiveSession()默认自己就是用户要操作的session，而tf.Session()没有这个默认，因此用eval()启动计算时需要指明session。加上初始化这些。最后设定了一下添加loss和accuracy的函数，并且每走一步加一，最后把loss和accuracy都打印出来。最后蓄念过程出现了一大堆结果，然后batch loss和accuracy都打印了出来。
```
# (Inline plots: )
%matplotlib inline
font = {
    'family' : 'Bitstream Vera Sans',
    'weight' : 'bold',
    'size'   : 18
}
matplotlib.rc('font', **font)
width = 12
height = 12
plt.figure(figsize=(width, height))

indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))
plt.plot(indep_train_axis, np.array(train_losses),     "b--", label="Train losses")
plt.plot(indep_train_axis, np.array(train_accuracies), "g--", label="Train accuracies")

indep_test_axis = np.append(
    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),
    [training_iters]
)
plt.plot(indep_test_axis, np.array(test_losses),     "b-", label="Test losses")
plt.plot(indep_test_axis, np.array(test_accuracies), "g-", label="Test accuracies")

plt.title("Training session's progress over iterations")
plt.legend(loc='upper right', shadow=True)
plt.ylabel('Training Progress (Loss or Accuracy values)')
plt.xlabel('Training iteration')
plt.show()
```
这个地方就是画图（结果也是出现的画图，而且用的还是matplotlib），按照训练迭代结果把对应指标从直方图中表示出来。
```
# Results

predictions = one_hot_predictions.argmax(1)

print("Testing Accuracy: {}%".format(100*accuracy))

print("")
print("Precision: {}%".format(100*metrics.precision_score(y_test, predictions, average="weighted")))
print("Recall: {}%".format(100*metrics.recall_score(y_test, predictions, average="weighted")))
print("f1_score: {}%".format(100*metrics.f1_score(y_test, predictions, average="weighted")))

print("")
print("Confusion Matrix:")
confusion_matrix = metrics.confusion_matrix(y_test, predictions)
print(confusion_matrix)
normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100

print("")
print("Confusion matrix (normalised to % of total test data):")
print(normalised_confusion_matrix)
print("Note: training and testing data is not equally distributed amongst classes, ")
print("so it is normal that more than a 6th of the data is correctly classifier in the last category.")

# Plot Results: 
width = 12
height = 12
plt.figure(figsize=(width, height))
plt.imshow(
    normalised_confusion_matrix, 
    interpolation='nearest', 
    cmap=plt.cm.rainbow
)
plt.title("Confusion matrix \n(normalised to % of total test data)")
plt.colorbar()
tick_marks = np.arange(n_classes)
plt.xticks(tick_marks, LABELS, rotation=90)
plt.yticks(tick_marks, LABELS)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
```
最后测得的测试准确度是88%（不懂怎么算出来的），最后也是把矩阵用数字表现了出来。
这个最后的准确率，感觉他只是能够根据具体的频段识别你是在干什么，是一个实时的，而不是说能够对一段视频进行具体的优化，关键一点是最后需要把指令输入到smartphone里？
最后数据集也快下完了，就等着看最后能不能训练好跑出视频（希望能做到吧，但是用cpu跑估计会非常慢）