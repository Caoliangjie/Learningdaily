## 3D Convolutional Neural Networks for Human Action Recognition阅读
今天开始这篇文章学习，并且作为今天paper reading的练习。
###　摘要
这篇文章是最基础的一篇，公式也没有，但是给出理论的话大体说不定能给我一个思路？CNN卷积原本只用于2D上，作者希望提出一种3D模型可以对于行为识别做出贡献，这种模型会产生许多输入框架的信息通道。
### 主要介绍
对于识别人类行为来说，作者提出了很多生活中可以用到的实例，一般来讲，以前的行为识别方法只能从最简单的两个步骤来确定：
1. 在原始的输入中提取复杂的人工特征。
2. 在获取的特征上学习分类器。
这里深度学习牛逼的地方就是因为他可以一开始就是一个深度模型，他对姿势，光照和复杂背景存在不变性。作者想法是把CNN从2D转到3D上去，看上去有些困难，因为第三个维度是时间而不是高度，比空间而讲其实还是还有一些困难的。
### 3D卷积网络
传统的做对于视频的处理来讲，就是把视频拆为一帧一帧的图片，每一帧用CNN来识别，对于这篇文章来说，是用3DCNN来进行，这里3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核，对于这个卷积层是后面的层特征map的个数应该增加，这样就可以从低级的特征maps组合产生更多类型的特征。
### 3DCNN 的结构
他的文章里给了一个比较清晰的图，3个卷积层，两个下采样层，1个全连接层，每个3D卷积核卷积的立方体是连续7帧，每帧patch大小是60x40。
第一层对一个固定的hardwired对原始的帧进行处理，每个帧有五个通道的信息，分别是：灰度，x和y方向的梯度，x和y方向的光流。前面三个都可以每帧都计算，然后水平和垂直方向的光流场需要两个连续帧才能确定。conv层，pooling层，这些都有。（CNN的基本层数）
到这个阶段，时间维上帧的个数已经很小了， (3 for gray, gradient-x, gradient-y, and 2 for optflow-x and optflow-y)。在这一层，我们只在空间维度上面卷积，这时候我们使用的核是7x4，然后输出的特征maps就被减小到1x1的大小。而C6层就包含有128个特征map，每个特征map与S5层中所有78（13x6）个特征maps全连接，这样每个特征map就是1x1，也就是一个值了，而这个就是最终的特征向量了。共128维。（先把图片用卷积扩展）
### model regularization
3DCNN模型输入被限制为一个少的连续视频帧，随着输入窗口大小的增加，模型需要的训练的参数也会增加，但是呢，很多人的行为是跨越很多帧的，训练过程中，是提取的特征更好的逼近这个计算好的高层的行为特征向量。（这个大哥用的是C++实现的，还是基于原始的CNN进行）
每一个需要训练的行为，我们提取其时间长短，然后构造一个时间序列之间的变化。本文的3D CNN模型用C++实现，它是属于NEC’s行为识别系统的一部分。关于CNN具体的实现细节是基于原始CNN的。所有的子采样层都是最大子采样。用于训练规则化模型的整体代价函数是由真实的行为类的误差和高层特征的辅助输入的代价项的线性加权得到。权值分别是1和0.005（经验值）。模型的所有参数都是随机初始化，然后通过随机diagonal Levenberg-Marquardt方法来优化训练。在这个方法中，先通过1千个随机采样的样本来得到一个近似Hessian矩阵的Gauss-Newton近似，然后使用它的对角项来决定每个参数的学习速率。