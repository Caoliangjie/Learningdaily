## CNN
尝试了一波吴老师CNN的习题...有点厉害，按照提示也不一定能弄出来。
### 对于卷积的计算
原始图是n*n的，fliter的尺寸是f*f的，那么卷积后图片尺寸为（n-f+1）*（n-f+1）的。
但是这样一般会导致图片格式变小，所以采用图片扩展（padding）的方法进行计算。
padding后图片的大小变为（n+2p）*（n+2p），其中p=(f-1)/2，对于多通道的图片，通道数经过变换后一般是不会变化的。
### CNN的优势
相比较而言，CNN的参数比传统神经网络要少得多。其一是因为参数共享，在一个是因为链接具有稀疏性。CNN最常见的层是conv层，又是最重要的。
## GAN的初步学习
网络大神说他就是一种无中生有的东西，这个我们昨天也有所探讨（一个G，一个D，两方进行冲突）。只不过昨天是进阶的DCGAN，今天这个相对基础一点。
随着训练的的推进，虚假的样本分布会逐渐与真是样本重合，D会不断更新。
### 模型认知
因为学习任务可以分为监督学习和无监督学习两类，GAN显然是属于无监督学习。因为他没有标记信息。
### 训练方式
基本的公式可以说也不是第一次看了，应该有一个基本的印象，对自己好。
大神看的论文用的是反向传播法。在训练过程中，没有任何求出真实样本的分布或是生成样本的分布的过程。
### GAN生成的最后意思？
他的意思是，生成器生成的都是假的，样本会不断渐变直到无限接近原始图像，然后我们之前那个风格转换的也可以看出来具体的情况。
### 优缺点
优点是计算得快，而且范围广泛。缺点是由于对于图片控制很自由，所以说在维度较大时，简单的方式不可控，而且难以继续训练。
## python练习
### 列表生成器
生成乘方的列表式子：[x*x,for x in range(1,11)]这里会生成1到10的乘方序列。python中一边循环一边计算的机制叫做generator。对于列表生成器只要把[]改成()就可以了。
### 函数式编程
map，filter，reduce,sorted的用法记住。